package com.tibtech.nifi.processors.kafka;

import groovy.lang.Closure;
import groovy.lang.DelegatesTo;
import java.lang.String;
import java.util.HashMap;
import java.util.Map;
import java.util.function.Function;

public final class PutKafka {
  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public static final String KNOWN_BROKERS_PROPERTY = "Known Brokers";

  /**
   * The Kafka Topic of interest
   */
  public static final String TOPIC_NAME_PROPERTY = "Topic Name";

  /**
   * Specifies how messages should be partitioned when sent to Kafka
   */
  public static final String PARTITION_STRATEGY_PROPERTY = "Partition Strategy";

  /**
   * Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.
   */
  public static final String PARTITION_PROPERTY = "Partition";

  /**
   * The Key to use for the Message
   */
  public static final String KAFKA_KEY_PROPERTY = "Kafka Key";

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka
   */
  public static final String DELIVERY_GUARANTEE_PROPERTY = "Delivery Guarantee";

  /**
   * Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.
   */
  public static final String MESSAGE_DELIMITER_PROPERTY = "Message Delimiter";

  /**
   * The maximum amount of data to buffer in memory before sending to Kafka
   */
  public static final String MAX_BUFFER_SIZE_PROPERTY = "Max Buffer Size";

  /**
   * The maximum size that any individual record can be.
   */
  public static final String MAX_RECORD_SIZE_PROPERTY = "Max Record Size";

  /**
   * The amount of time to wait for a response from Kafka before determining that there is a communications error
   */
  public static final String COMMUNICATIONS_TIMEOUT_PROPERTY = "Communications Timeout";

  /**
   * This configuration controls the default batch size in bytes.The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server.
   */
  public static final String ASYNC_BATCH_SIZE_PROPERTY = "Async Batch Size";

  /**
   * Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.
   */
  public static final String QUEUE_BUFFERING_MAX_TIME_PROPERTY = "Queue Buffering Max Time";

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public static final String COMPRESSION_CODEC_PROPERTY = "Compression Codec";

  /**
   * Client Name to use when communicating with Kafka
   */
  public static final String CLIENT_NAME_PROPERTY = "Client Name";

  private final Map<String, String> properties = new HashMap<String, String>();

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final String getKnownBrokers() {
    return properties.get(KNOWN_BROKERS_PROPERTY);
  }

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final PutKafka setKnownBrokers(final String knownBrokers) {
    properties.put(KNOWN_BROKERS_PROPERTY, knownBrokers);
    return this;
  }

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final PutKafka removeKnownBrokers() {
    properties.remove(KNOWN_BROKERS_PROPERTY);
    return this;
  }

  /**
   * The Kafka Topic of interest
   */
  public final String getTopicName() {
    return properties.get(TOPIC_NAME_PROPERTY);
  }

  /**
   * The Kafka Topic of interest
   */
  public final PutKafka setTopicName(final String topicName) {
    properties.put(TOPIC_NAME_PROPERTY, topicName);
    return this;
  }

  /**
   * The Kafka Topic of interest
   */
  public final PutKafka removeTopicName() {
    properties.remove(TOPIC_NAME_PROPERTY);
    return this;
  }

  /**
   * Specifies how messages should be partitioned when sent to Kafka
   */
  public final String getPartitionStrategy() {
    return properties.get(PARTITION_STRATEGY_PROPERTY);
  }

  /**
   * Specifies how messages should be partitioned when sent to Kafka
   */
  public final PutKafka setPartitionStrategy(final String partitionStrategy) {
    properties.put(PARTITION_STRATEGY_PROPERTY, partitionStrategy);
    return this;
  }

  /**
   * Specifies how messages should be partitioned when sent to Kafka
   */
  public final PutKafka removePartitionStrategy() {
    properties.remove(PARTITION_STRATEGY_PROPERTY);
    return this;
  }

  /**
   * Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.
   */
  public final String getPartition() {
    return properties.get(PARTITION_PROPERTY);
  }

  /**
   * Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.
   */
  public final PutKafka setPartition(final String partition) {
    properties.put(PARTITION_PROPERTY, partition);
    return this;
  }

  /**
   * Specifies which Kafka Partition to add the message to. If using a message delimiter, all messages in the same FlowFile will be sent to the same partition. If a partition is specified but is not valid, then all messages within the same FlowFile will use the same partition but it remains undefined which partition is used.
   */
  public final PutKafka removePartition() {
    properties.remove(PARTITION_PROPERTY);
    return this;
  }

  /**
   * The Key to use for the Message
   */
  public final String getKafkaKey() {
    return properties.get(KAFKA_KEY_PROPERTY);
  }

  /**
   * The Key to use for the Message
   */
  public final PutKafka setKafkaKey(final String kafkaKey) {
    properties.put(KAFKA_KEY_PROPERTY, kafkaKey);
    return this;
  }

  /**
   * The Key to use for the Message
   */
  public final PutKafka removeKafkaKey() {
    properties.remove(KAFKA_KEY_PROPERTY);
    return this;
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka
   */
  public final String getDeliveryGuarantee() {
    return properties.get(DELIVERY_GUARANTEE_PROPERTY);
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka
   */
  public final PutKafka setDeliveryGuarantee(final String deliveryGuarantee) {
    properties.put(DELIVERY_GUARANTEE_PROPERTY, deliveryGuarantee);
    return this;
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka
   */
  public final PutKafka removeDeliveryGuarantee() {
    properties.remove(DELIVERY_GUARANTEE_PROPERTY);
    return this;
  }

  /**
   * Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.
   */
  public final String getMessageDelimiter() {
    return properties.get(MESSAGE_DELIMITER_PROPERTY);
  }

  /**
   * Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.
   */
  public final PutKafka setMessageDelimiter(final String messageDelimiter) {
    properties.put(MESSAGE_DELIMITER_PROPERTY, messageDelimiter);
    return this;
  }

  /**
   * Specifies the delimiter (interpreted in its UTF-8 byte representation) to use for splitting apart multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. Note that if messages are delimited and some messages for a given FlowFile are transferred successfully while others are not, the messages will be split into individual FlowFiles, such that those messages that were successfully sent are routed to the 'success' relationship while other messages are sent to the 'failure' relationship.
   */
  public final PutKafka removeMessageDelimiter() {
    properties.remove(MESSAGE_DELIMITER_PROPERTY);
    return this;
  }

  /**
   * The maximum amount of data to buffer in memory before sending to Kafka
   */
  public final String getMaxBufferSize() {
    return properties.get(MAX_BUFFER_SIZE_PROPERTY);
  }

  /**
   * The maximum amount of data to buffer in memory before sending to Kafka
   */
  public final PutKafka setMaxBufferSize(final String maxBufferSize) {
    properties.put(MAX_BUFFER_SIZE_PROPERTY, maxBufferSize);
    return this;
  }

  /**
   * The maximum amount of data to buffer in memory before sending to Kafka
   */
  public final PutKafka removeMaxBufferSize() {
    properties.remove(MAX_BUFFER_SIZE_PROPERTY);
    return this;
  }

  /**
   * The maximum size that any individual record can be.
   */
  public final String getMaxRecordSize() {
    return properties.get(MAX_RECORD_SIZE_PROPERTY);
  }

  /**
   * The maximum size that any individual record can be.
   */
  public final PutKafka setMaxRecordSize(final String maxRecordSize) {
    properties.put(MAX_RECORD_SIZE_PROPERTY, maxRecordSize);
    return this;
  }

  /**
   * The maximum size that any individual record can be.
   */
  public final PutKafka removeMaxRecordSize() {
    properties.remove(MAX_RECORD_SIZE_PROPERTY);
    return this;
  }

  /**
   * The amount of time to wait for a response from Kafka before determining that there is a communications error
   */
  public final String getCommunicationsTimeout() {
    return properties.get(COMMUNICATIONS_TIMEOUT_PROPERTY);
  }

  /**
   * The amount of time to wait for a response from Kafka before determining that there is a communications error
   */
  public final PutKafka setCommunicationsTimeout(final String communicationsTimeout) {
    properties.put(COMMUNICATIONS_TIMEOUT_PROPERTY, communicationsTimeout);
    return this;
  }

  /**
   * The amount of time to wait for a response from Kafka before determining that there is a communications error
   */
  public final PutKafka removeCommunicationsTimeout() {
    properties.remove(COMMUNICATIONS_TIMEOUT_PROPERTY);
    return this;
  }

  /**
   * This configuration controls the default batch size in bytes.The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server.
   */
  public final String getAsyncBatchSize() {
    return properties.get(ASYNC_BATCH_SIZE_PROPERTY);
  }

  /**
   * This configuration controls the default batch size in bytes.The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server.
   */
  public final PutKafka setAsyncBatchSize(final String asyncBatchSize) {
    properties.put(ASYNC_BATCH_SIZE_PROPERTY, asyncBatchSize);
    return this;
  }

  /**
   * This configuration controls the default batch size in bytes.The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server.
   */
  public final PutKafka removeAsyncBatchSize() {
    properties.remove(ASYNC_BATCH_SIZE_PROPERTY);
    return this;
  }

  /**
   * Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.
   */
  public final String getQueueBufferingMaxTime() {
    return properties.get(QUEUE_BUFFERING_MAX_TIME_PROPERTY);
  }

  /**
   * Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.
   */
  public final PutKafka setQueueBufferingMaxTime(final String queueBufferingMaxTime) {
    properties.put(QUEUE_BUFFERING_MAX_TIME_PROPERTY, queueBufferingMaxTime);
    return this;
  }

  /**
   * Maximum time to buffer data before sending to Kafka. For example a setting of 100 ms will try to batch together 100 milliseconds' worth of messages to send at once. This will improve throughput but adds message delivery latency due to the buffering.
   */
  public final PutKafka removeQueueBufferingMaxTime() {
    properties.remove(QUEUE_BUFFERING_MAX_TIME_PROPERTY);
    return this;
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final String getCompressionCodec() {
    return properties.get(COMPRESSION_CODEC_PROPERTY);
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final PutKafka setCompressionCodec(final String compressionCodec) {
    properties.put(COMPRESSION_CODEC_PROPERTY, compressionCodec);
    return this;
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final PutKafka removeCompressionCodec() {
    properties.remove(COMPRESSION_CODEC_PROPERTY);
    return this;
  }

  /**
   * Client Name to use when communicating with Kafka
   */
  public final String getClientName() {
    return properties.get(CLIENT_NAME_PROPERTY);
  }

  /**
   * Client Name to use when communicating with Kafka
   */
  public final PutKafka setClientName(final String clientName) {
    properties.put(CLIENT_NAME_PROPERTY, clientName);
    return this;
  }

  /**
   * Client Name to use when communicating with Kafka
   */
  public final PutKafka removeClientName() {
    properties.remove(CLIENT_NAME_PROPERTY);
    return this;
  }

  public final String getDynamicProperty(final String name) {
    return properties.get(name);
  }

  public final PutKafka setDynamicProperty(final String name, final String value) {
    properties.put(name, value);
    return this;
  }

  public final PutKafka removeDynamicProperty(final String name) {
    properties.remove(name);
    return this;
  }

  public final Map<String, String> build() {
    return properties;
  }

  public static final Map<String, String> build(final Function<PutKafka, PutKafka> configurator) {
    return configurator.apply(new PutKafka()).build();
  }

  public static final Map<String, String> build(@DelegatesTo(strategy = Closure.DELEGATE_ONLY, value = PutKafka.class) final Closure<PutKafka> closure) {
    return build(c -> {
      final Closure<com.tibtech.nifi.processors.kafka.PutKafka> code = closure.rehydrate(c, com.tibtech.nifi.processors.kafka.PutKafka.class, com.tibtech.nifi.processors.kafka.PutKafka.class);
      code.setResolveStrategy(Closure.DELEGATE_ONLY);
      code.call();
      return c;
    } );
  }
}
