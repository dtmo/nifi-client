package com.tibtech.nifi.processors.kafka.pubsub;

import groovy.lang.Closure;
import groovy.lang.DelegatesTo;
import java.lang.String;
import java.util.HashMap;
import java.util.Map;
import java.util.function.Function;

public final class PublishKafka_0_10 {
  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public static final String BOOTSTRAPSERVERS_PROPERTY = "bootstrap.servers";

  /**
   * Protocol used to communicate with brokers. Corresponds to Kafka's 'security.protocol' property.
   */
  public static final String SECURITYPROTOCOL_PROPERTY = "security.protocol";

  /**
   * The Kerberos principal name that Kafka runs as. This can be defined either in Kafka's JAAS config or in Kafka's config. Corresponds to Kafka's 'security.protocol' property.It is ignored unless one of the SASL options of the <Security Protocol> are selected.
   */
  public static final String SASLKERBEROSSERVICENAME_PROPERTY = "sasl.kerberos.service.name";

  /**
   * Specifies the SSL Context Service to use for communicating with Kafka.
   */
  public static final String SSLCONTEXTSERVICE_PROPERTY = "ssl.context.service";

  /**
   * The name of the Kafka Topic to publish to.
   */
  public static final String TOPIC_PROPERTY = "topic";

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka. Corresponds to Kafka's 'acks' property.
   */
  public static final String ACKS_PROPERTY = "acks";

  /**
   * The Key to use for the Message. If not specified, the flow file attribute 'kafka.key' is used as the message key, if it is present and we're not demarcating.
   */
  public static final String KAFKA_KEY_PROPERTY = "kafka-key";

  /**
   * FlowFiles that are emitted have an attribute named 'kafka.key'. This property dictates how the value of the attribute should be encoded.
   */
  public static final String KEY_ATTRIBUTE_ENCODING_PROPERTY = "key-attribute-encoding";

  /**
   * Specifies the string (interpreted as UTF-8) to use for demarcating multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. To enter special character such as 'new line' use CTRL+Enter or Shift+Enter, depending on your OS.
   */
  public static final String MESSAGE_DEMARCATOR_PROPERTY = "message-demarcator";

  /**
   * The maximum size of a request in bytes. Corresponds to Kafka's 'max.request.size' property and defaults to 1 MB (1048576).
   */
  public static final String MAXREQUESTSIZE_PROPERTY = "max.request.size";

  /**
   * After sending a message to Kafka, this indicates the amount of time that we are willing to wait for a response from Kafka. If Kafka does not acknowledge the message within this time period, the FlowFile will be routed to 'failure'.
   */
  public static final String ACKWAITTIME_PROPERTY = "ack.wait.time";

  /**
   * The amount of time publisher will wait to obtain metadata or wait for the buffer to flush during the 'send' call before failing the entire 'send' call. Corresponds to Kafka's 'max.block.ms' property
   */
  public static final String MAXBLOCKMS_PROPERTY = "max.block.ms";

  /**
   * Specifies which class to use to compute a partition id for a message. Corresponds to Kafka's 'partitioner.class' property.
   */
  public static final String PARTITIONERCLASS_PROPERTY = "partitioner.class";

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public static final String COMPRESSIONTYPE_PROPERTY = "compression.type";

  private final Map<String, String> properties = new HashMap<String, String>();

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final String getBootstrapservers() {
    return properties.get(BOOTSTRAPSERVERS_PROPERTY);
  }

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final PublishKafka_0_10 setBootstrapservers(final String bootstrapservers) {
    properties.put(BOOTSTRAPSERVERS_PROPERTY, bootstrapservers);
    return this;
  }

  /**
   * A comma-separated list of known Kafka Brokers in the format <host>:<port>
   */
  public final PublishKafka_0_10 removeBootstrapservers() {
    properties.remove(BOOTSTRAPSERVERS_PROPERTY);
    return this;
  }

  /**
   * Protocol used to communicate with brokers. Corresponds to Kafka's 'security.protocol' property.
   */
  public final String getSecurityprotocol() {
    return properties.get(SECURITYPROTOCOL_PROPERTY);
  }

  /**
   * Protocol used to communicate with brokers. Corresponds to Kafka's 'security.protocol' property.
   */
  public final PublishKafka_0_10 setSecurityprotocol(final String securityprotocol) {
    properties.put(SECURITYPROTOCOL_PROPERTY, securityprotocol);
    return this;
  }

  /**
   * Protocol used to communicate with brokers. Corresponds to Kafka's 'security.protocol' property.
   */
  public final PublishKafka_0_10 removeSecurityprotocol() {
    properties.remove(SECURITYPROTOCOL_PROPERTY);
    return this;
  }

  /**
   * The Kerberos principal name that Kafka runs as. This can be defined either in Kafka's JAAS config or in Kafka's config. Corresponds to Kafka's 'security.protocol' property.It is ignored unless one of the SASL options of the <Security Protocol> are selected.
   */
  public final String getSaslkerberosservicename() {
    return properties.get(SASLKERBEROSSERVICENAME_PROPERTY);
  }

  /**
   * The Kerberos principal name that Kafka runs as. This can be defined either in Kafka's JAAS config or in Kafka's config. Corresponds to Kafka's 'security.protocol' property.It is ignored unless one of the SASL options of the <Security Protocol> are selected.
   */
  public final PublishKafka_0_10 setSaslkerberosservicename(final String saslkerberosservicename) {
    properties.put(SASLKERBEROSSERVICENAME_PROPERTY, saslkerberosservicename);
    return this;
  }

  /**
   * The Kerberos principal name that Kafka runs as. This can be defined either in Kafka's JAAS config or in Kafka's config. Corresponds to Kafka's 'security.protocol' property.It is ignored unless one of the SASL options of the <Security Protocol> are selected.
   */
  public final PublishKafka_0_10 removeSaslkerberosservicename() {
    properties.remove(SASLKERBEROSSERVICENAME_PROPERTY);
    return this;
  }

  /**
   * Specifies the SSL Context Service to use for communicating with Kafka.
   */
  public final String getSslcontextservice() {
    return properties.get(SSLCONTEXTSERVICE_PROPERTY);
  }

  /**
   * Specifies the SSL Context Service to use for communicating with Kafka.
   */
  public final PublishKafka_0_10 setSslcontextservice(final String sslcontextservice) {
    properties.put(SSLCONTEXTSERVICE_PROPERTY, sslcontextservice);
    return this;
  }

  /**
   * Specifies the SSL Context Service to use for communicating with Kafka.
   */
  public final PublishKafka_0_10 removeSslcontextservice() {
    properties.remove(SSLCONTEXTSERVICE_PROPERTY);
    return this;
  }

  /**
   * The name of the Kafka Topic to publish to.
   */
  public final String getTopic() {
    return properties.get(TOPIC_PROPERTY);
  }

  /**
   * The name of the Kafka Topic to publish to.
   */
  public final PublishKafka_0_10 setTopic(final String topic) {
    properties.put(TOPIC_PROPERTY, topic);
    return this;
  }

  /**
   * The name of the Kafka Topic to publish to.
   */
  public final PublishKafka_0_10 removeTopic() {
    properties.remove(TOPIC_PROPERTY);
    return this;
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka. Corresponds to Kafka's 'acks' property.
   */
  public final String getAcks() {
    return properties.get(ACKS_PROPERTY);
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka. Corresponds to Kafka's 'acks' property.
   */
  public final PublishKafka_0_10 setAcks(final String acks) {
    properties.put(ACKS_PROPERTY, acks);
    return this;
  }

  /**
   * Specifies the requirement for guaranteeing that a message is sent to Kafka. Corresponds to Kafka's 'acks' property.
   */
  public final PublishKafka_0_10 removeAcks() {
    properties.remove(ACKS_PROPERTY);
    return this;
  }

  /**
   * The Key to use for the Message. If not specified, the flow file attribute 'kafka.key' is used as the message key, if it is present and we're not demarcating.
   */
  public final String getKafkaKey() {
    return properties.get(KAFKA_KEY_PROPERTY);
  }

  /**
   * The Key to use for the Message. If not specified, the flow file attribute 'kafka.key' is used as the message key, if it is present and we're not demarcating.
   */
  public final PublishKafka_0_10 setKafkaKey(final String kafkaKey) {
    properties.put(KAFKA_KEY_PROPERTY, kafkaKey);
    return this;
  }

  /**
   * The Key to use for the Message. If not specified, the flow file attribute 'kafka.key' is used as the message key, if it is present and we're not demarcating.
   */
  public final PublishKafka_0_10 removeKafkaKey() {
    properties.remove(KAFKA_KEY_PROPERTY);
    return this;
  }

  /**
   * FlowFiles that are emitted have an attribute named 'kafka.key'. This property dictates how the value of the attribute should be encoded.
   */
  public final String getKeyAttributeEncoding() {
    return properties.get(KEY_ATTRIBUTE_ENCODING_PROPERTY);
  }

  /**
   * FlowFiles that are emitted have an attribute named 'kafka.key'. This property dictates how the value of the attribute should be encoded.
   */
  public final PublishKafka_0_10 setKeyAttributeEncoding(final String keyAttributeEncoding) {
    properties.put(KEY_ATTRIBUTE_ENCODING_PROPERTY, keyAttributeEncoding);
    return this;
  }

  /**
   * FlowFiles that are emitted have an attribute named 'kafka.key'. This property dictates how the value of the attribute should be encoded.
   */
  public final PublishKafka_0_10 removeKeyAttributeEncoding() {
    properties.remove(KEY_ATTRIBUTE_ENCODING_PROPERTY);
    return this;
  }

  /**
   * Specifies the string (interpreted as UTF-8) to use for demarcating multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. To enter special character such as 'new line' use CTRL+Enter or Shift+Enter, depending on your OS.
   */
  public final String getMessageDemarcator() {
    return properties.get(MESSAGE_DEMARCATOR_PROPERTY);
  }

  /**
   * Specifies the string (interpreted as UTF-8) to use for demarcating multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. To enter special character such as 'new line' use CTRL+Enter or Shift+Enter, depending on your OS.
   */
  public final PublishKafka_0_10 setMessageDemarcator(final String messageDemarcator) {
    properties.put(MESSAGE_DEMARCATOR_PROPERTY, messageDemarcator);
    return this;
  }

  /**
   * Specifies the string (interpreted as UTF-8) to use for demarcating multiple messages within a single FlowFile. If not specified, the entire content of the FlowFile will be used as a single message. If specified, the contents of the FlowFile will be split on this delimiter and each section sent as a separate Kafka message. To enter special character such as 'new line' use CTRL+Enter or Shift+Enter, depending on your OS.
   */
  public final PublishKafka_0_10 removeMessageDemarcator() {
    properties.remove(MESSAGE_DEMARCATOR_PROPERTY);
    return this;
  }

  /**
   * The maximum size of a request in bytes. Corresponds to Kafka's 'max.request.size' property and defaults to 1 MB (1048576).
   */
  public final String getMaxrequestsize() {
    return properties.get(MAXREQUESTSIZE_PROPERTY);
  }

  /**
   * The maximum size of a request in bytes. Corresponds to Kafka's 'max.request.size' property and defaults to 1 MB (1048576).
   */
  public final PublishKafka_0_10 setMaxrequestsize(final String maxrequestsize) {
    properties.put(MAXREQUESTSIZE_PROPERTY, maxrequestsize);
    return this;
  }

  /**
   * The maximum size of a request in bytes. Corresponds to Kafka's 'max.request.size' property and defaults to 1 MB (1048576).
   */
  public final PublishKafka_0_10 removeMaxrequestsize() {
    properties.remove(MAXREQUESTSIZE_PROPERTY);
    return this;
  }

  /**
   * After sending a message to Kafka, this indicates the amount of time that we are willing to wait for a response from Kafka. If Kafka does not acknowledge the message within this time period, the FlowFile will be routed to 'failure'.
   */
  public final String getAckwaittime() {
    return properties.get(ACKWAITTIME_PROPERTY);
  }

  /**
   * After sending a message to Kafka, this indicates the amount of time that we are willing to wait for a response from Kafka. If Kafka does not acknowledge the message within this time period, the FlowFile will be routed to 'failure'.
   */
  public final PublishKafka_0_10 setAckwaittime(final String ackwaittime) {
    properties.put(ACKWAITTIME_PROPERTY, ackwaittime);
    return this;
  }

  /**
   * After sending a message to Kafka, this indicates the amount of time that we are willing to wait for a response from Kafka. If Kafka does not acknowledge the message within this time period, the FlowFile will be routed to 'failure'.
   */
  public final PublishKafka_0_10 removeAckwaittime() {
    properties.remove(ACKWAITTIME_PROPERTY);
    return this;
  }

  /**
   * The amount of time publisher will wait to obtain metadata or wait for the buffer to flush during the 'send' call before failing the entire 'send' call. Corresponds to Kafka's 'max.block.ms' property
   */
  public final String getMaxblockms() {
    return properties.get(MAXBLOCKMS_PROPERTY);
  }

  /**
   * The amount of time publisher will wait to obtain metadata or wait for the buffer to flush during the 'send' call before failing the entire 'send' call. Corresponds to Kafka's 'max.block.ms' property
   */
  public final PublishKafka_0_10 setMaxblockms(final String maxblockms) {
    properties.put(MAXBLOCKMS_PROPERTY, maxblockms);
    return this;
  }

  /**
   * The amount of time publisher will wait to obtain metadata or wait for the buffer to flush during the 'send' call before failing the entire 'send' call. Corresponds to Kafka's 'max.block.ms' property
   */
  public final PublishKafka_0_10 removeMaxblockms() {
    properties.remove(MAXBLOCKMS_PROPERTY);
    return this;
  }

  /**
   * Specifies which class to use to compute a partition id for a message. Corresponds to Kafka's 'partitioner.class' property.
   */
  public final String getPartitionerclass() {
    return properties.get(PARTITIONERCLASS_PROPERTY);
  }

  /**
   * Specifies which class to use to compute a partition id for a message. Corresponds to Kafka's 'partitioner.class' property.
   */
  public final PublishKafka_0_10 setPartitionerclass(final String partitionerclass) {
    properties.put(PARTITIONERCLASS_PROPERTY, partitionerclass);
    return this;
  }

  /**
   * Specifies which class to use to compute a partition id for a message. Corresponds to Kafka's 'partitioner.class' property.
   */
  public final PublishKafka_0_10 removePartitionerclass() {
    properties.remove(PARTITIONERCLASS_PROPERTY);
    return this;
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final String getCompressiontype() {
    return properties.get(COMPRESSIONTYPE_PROPERTY);
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final PublishKafka_0_10 setCompressiontype(final String compressiontype) {
    properties.put(COMPRESSIONTYPE_PROPERTY, compressiontype);
    return this;
  }

  /**
   * This parameter allows you to specify the compression codec for all data generated by this producer.
   */
  public final PublishKafka_0_10 removeCompressiontype() {
    properties.remove(COMPRESSIONTYPE_PROPERTY);
    return this;
  }

  public final String getDynamicProperty(final String name) {
    return properties.get(name);
  }

  public final PublishKafka_0_10 setDynamicProperty(final String name, final String value) {
    properties.put(name, value);
    return this;
  }

  public final PublishKafka_0_10 removeDynamicProperty(final String name) {
    properties.remove(name);
    return this;
  }

  public final Map<String, String> build() {
    return properties;
  }

  public static final Map<String, String> build(final Function<PublishKafka_0_10, PublishKafka_0_10> configurator) {
    return configurator.apply(new PublishKafka_0_10()).build();
  }

  public static final Map<String, String> build(@DelegatesTo(strategy = Closure.DELEGATE_ONLY, value = PublishKafka_0_10.class) final Closure<PublishKafka_0_10> closure) {
    return build(c -> {
      final Closure<com.tibtech.nifi.processors.kafka.pubsub.PublishKafka_0_10> code = closure.rehydrate(c, com.tibtech.nifi.processors.kafka.pubsub.PublishKafka_0_10.class, com.tibtech.nifi.processors.kafka.pubsub.PublishKafka_0_10.class);
      code.setResolveStrategy(Closure.DELEGATE_ONLY);
      code.call();
      return c;
    } );
  }
}
